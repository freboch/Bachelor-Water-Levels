{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0e1f296-b9df-4a32-92c8-5e37bc2beea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "from eval_model_plots import *\n",
    "from synth_data_samples import get_synth_data_sample, get_synth_lake\n",
    "\n",
    "import random\n",
    "random.seed(23846)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9d10699-3149-4bdf-ba67-690ebced93e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which data\n",
    "# random\n",
    "data_set = 'random'\n",
    "size = 5000\n",
    "\n",
    "# synthetic 3D 1-6\n",
    "#data_set = 1\n",
    "\n",
    "# synthetic lake\n",
    "#data_set = 'synth lakes'\n",
    "#size=5000\n",
    "#dim = 48\n",
    "\n",
    "# Lake\n",
    "#data_set = 'lakes'\n",
    "#size = 6296 #6607\n",
    "#data_set = 'lakes nn'\n",
    "#size = 6315\n",
    "#data_set = 'lakes select'\n",
    "#size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9969ac1-9f3a-416a-a554-1e307ec233eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "archetypes = None\n",
    "if isinstance(data_set, int):\n",
    "    archetypes, _, _, size, _ = get_synth_data_sample(data_set)\n",
    "if data_set == 'synth lakes':\n",
    "    archetypes, _, _, _, _ = get_synth_lake(size,dim)\n",
    "    #plot_data(archetypes,'Synthetic lake archetypes', projected=False)\n",
    "    #plot_data(archetypes,'Synthetic lake archetypes', projected=True)\n",
    "# archetypes\n",
    "K = np.arange(2,11)\n",
    "# sets\n",
    "J = 5\n",
    "# re-initialisations per set\n",
    "L = 50\n",
    "# epochs for training\n",
    "n_epoch = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bc9d82a-12fa-4eb7-b94c-862155b825ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved full dict\n"
     ]
    }
   ],
   "source": [
    "res = dict()\n",
    "models = ['DAA', 'AA', 'NMF', 'GMM']\n",
    "for model in models:\n",
    "    folder = f'saves/data{data_set}_size{size}_arc{len(K)}_sets{J}_init{L}_epoch{n_epoch}'\n",
    "    file = folder + f'/res_dict_model{model}_data{data_set}_size{size}_arc{len(K)}_sets{J}_init{L}_epoch{n_epoch}.pkl'\n",
    "    with open(file, 'rb') as f:\n",
    "            res_model = pickle.load(f)\n",
    "    for key in res_model.keys():\n",
    "        res[key] = res_model[key]\n",
    "        \n",
    "# save the combined dictionary\n",
    "folder = f\"saves/data{data_set}_size{size}_arc{len(K)}_sets{J}_init{L}_epoch{n_epoch}\"\n",
    "filename = folder + f'/res_dict_data{data_set}_size{size}_arc{len(K)}_sets{J}_init{L}_epoch{n_epoch}.pkl'\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(res, f)\n",
    "print('saved full dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3436a23f-e6a3-44a4-9332-bbb8ac378de2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
